{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is Software Testing?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### - Software testing is the process of evaluating the quality of a software product by identifying defects and reducing the risk of failure in a real-world operational environment.  \n",
    "##### - Testing is not just about verification; validation is equally important.  \n",
    "##### - **Verification** ensures that the work products (e.g., requirements, design, code) are implemented correctly as per the specified requirements.  \n",
    "##### - **Validation** confirms that the final product meets stakeholder and user expectations in the production environment.  \n",
    "##### - Testing is an **intellectual activity** that involves planning, designing, executing, monitoring, and evaluating tests. It is not just about running test cases but ensuring software reliability, performance, and usability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test object\n",
    "# the test object is the system or the component being tested. \n",
    "# for example : it can be a feature, api, module or entire application being tested\n",
    "\n",
    "# test ware\n",
    "# testware refers to all the artifacts created, used, and maintained for testing. It includes test cases, test scripts, test environments, test plans and test reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test Object\n",
    "- The Test Object is the system or component being tested.\n",
    "- It can be a feature, module, API, database, or an entire application that is under test.\n",
    "- Example: In an e-commerce application, the shopping cart functionality can be a test object.\n",
    "2. Testware\n",
    "- Testware refers to all the artifacts created, used, and maintained for testing.\n",
    "- It includes test cases, test scripts, test data, test environments, test plans, and test reports.\n",
    "- Example: A Selenium automation script written for a login page is part of testware.\n",
    "3. Work Product\n",
    "- A Work Product is any deliverable produced during the software development lifecycle (SDLC), including testing.\n",
    "- Work products can be documents, code, test cases, test plans, and reports.\n",
    "- Example: A Test Summary Report generated after test execution is a work product.\n",
    "4. Test Basis\n",
    "- The Test Basis is the source of information used to create test cases.\n",
    "- It includes requirements, architecture diagrams, user stories, specifications, and design documents.\n",
    "- Example: A functional specification document that describes how the login page should work is part of the test basis.\n",
    "5. Test Condition\n",
    "- A Test Condition is a specific requirement, function, or feature that needs to be tested.\n",
    "- It is derived from the test basis.\n",
    "- Example: \"The login page should display an error message for incorrect passwords\" is a test condition.\n",
    "6. Test Case\n",
    "- A Test Case is a set of steps, inputs, and expected results used to validate a specific test condition.\n",
    "- Example: A test case for user login may include steps like entering a username and password and verifying if the user logs in successfully.\n",
    "7. Test Script\n",
    "- A Test Script is an automated script written to execute test cases.\n",
    "- Example: A Python Selenium script that tests the login functionality.\n",
    "8. Test Environment\n",
    "- A Test Environment is the setup required to execute tests, including hardware, software, databases, network configurations, and test data.\n",
    "- Example: A staging server that mimics production for testing.\n",
    "9. Test Data\n",
    "- Test Data refers to the inputs provided during testing to validate system behavior.\n",
    "- Example: A set of valid and invalid user credentials for login testing.\n",
    "10. Test Log\n",
    "- A Test Log records details of executed tests, including results, execution time, and errors.\n",
    "- Example: A log file showing which test cases passed or failed.\n",
    "11. Test Oracle\n",
    "- A Test Oracle is a mechanism to determine expected results for test cases.\n",
    "- Example: A requirement document that defines how the system should behave.\n",
    "12. Test Report\n",
    "- A Test Report summarizes test execution results, defects found, and overall testing status.\n",
    "- Example: A QA test summary report after a sprint release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test objectives - \n",
    "these are some objectives to keep in mind while testing the test product\n",
    "\n",
    "- evaluate the work products -  requirements, design documents, code, user stories\n",
    "verify whether the requirements are complete, clear and in testable format\n",
    "verify the design documents for consistency design\n",
    "coding check for the logical errors\n",
    "\n",
    "- make the system failure testing format, design the test in a way the system triggers failures\n",
    "\n",
    "- ensure the test object has enough test coverage\n",
    "\n",
    "- ensure the requirements specified are implemented and validate the work products\n",
    "\n",
    "- compliance with the standards\n",
    "\n",
    "- give stake holders decision making information \n",
    "\n",
    "- give confidence on the work product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing and Debugging\n",
    "\n",
    "- why testing is necessary ?\n",
    "testing acts as an quality control, which helps to achieve the agreed specified requirements with in the specified time, scope and with resources available\n",
    "in testing we try to trigger the failures caused by the system due to the defects in the system\n",
    "in testing we try to do the dynamic and static testing\n",
    "\n",
    "dynamic testing is the testing we do on the software, if an failure occurs in dynamic testing, we try to debug the root cause and elimnate the defect\n",
    "\n",
    "debugging is more to do with finding the root cause of the defects \n",
    "\n",
    "after dynamic testing, we have to do the regression testing on the parts of the system where the dependenics are there and ensure the existing functionalites are not broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing and QA\n",
    "- testing is more to do with the product focused, where we try to implement different methods and startergy to test the work product\n",
    "\n",
    "- qa is more to do with the process focused, the test design and implementation and improvement of the process.\n",
    "\n",
    "test results are used both in the testing and qa, in qa it helps to improve the process and identify the process that didn't work out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, defects, failures\n",
    "\n",
    "- error are human made in the code or in the system, which triggers the defects, these defects triggers the system failures\n",
    "\n",
    "defects can exist in various work products\n",
    "\n",
    "- not all defects lead to failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven principles of testing\n",
    "\n",
    "- testing shows the presence of defects not the absence of defects\n",
    "- exhaustive testing is impossible\n",
    "- defect clustering\n",
    "- absence of defect fallacy\n",
    "- testing is context dependent\n",
    "- test ware outs\n",
    "- early testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typical test activity \n",
    "\n",
    "- test planning = design the test plan, scope, entry and exit criterias, resources, startergy\n",
    "- test mointoring = what to assign to whom and what the status on the Work\n",
    "- test analysis = analyze the requirements properly and the dependencies for the testing\n",
    "- test design = test cases and test data prepare and methods\n",
    "- test implementation and execution = start testing and reporting the details\n",
    "- test completion - reporting the test results, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test ware - these are the artificats produced as part of the testing activities\n",
    "\n",
    "- test planning - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
